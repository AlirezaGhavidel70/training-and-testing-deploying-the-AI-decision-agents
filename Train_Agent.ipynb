{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlirezaGhavidel70/training-and-testing-deploying-the-AI-decision-agents/blob/main/Train_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP-jToEzmXgs"
      },
      "outputs": [],
      "source": [
        "# @ Authors: Ao Du and Alireza Ghavidel\n",
        "# This code trains an AI agent based on the user inputs\n",
        "###############################################################################\n",
        "################# User input values for trainig the AI-agent ##################\n",
        "###############################################################################\n",
        "\n",
        "# Specify the life horizon of the bridge\n",
        "life_span = 30\n",
        "# contribution weights of indirect cost\n",
        "w1=0.05\n",
        "# Please specify the city: Mamphis (0) or San Francisco =1\n",
        "City = 0 # seismic region: 0: Memphis, 1: San Francisco, 2: other cities (you need to define the corresponding hazard curve)\n",
        "# consider retrofiting\n",
        "steel_lacketing = False # if there is steel jacketing retrofiting use \"True\" otherwise it should be \"False\"\n",
        "seat_extender = False # if there is seat extender retrofiting use \"True\" otherwise it should be \"False\"\n",
        "shear_key = False # if there is shear key retrofiting use \"True\" otherwise it should be \"False\"\n",
        "\n",
        "# Specify the number of episodes to train the agent\n",
        "num_episodes = int(40000)\n",
        "\n",
        "\n",
        "## Hyperparameters and Utilities\n",
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# LR is the learning rate of the ``Adam`` optimizer\n",
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.96\n",
        "EPS_START = 1.0\n",
        "EPS_END = 0.01\n",
        "EPS_DECAY = 5000\n",
        "LR = 1e-2\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code starts from here*-\n",
        "\"\"\"\n",
        "Fragility curves and risk analysis are incorporated in this code to find the earthquake damage state probabilities\n",
        "\n",
        "@author: Alireza Ghavidel\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import scipy\n",
        "import sympy\n",
        "from scipy import special\n",
        "from sympy import *\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import derivative\n",
        "from scipy import *\n",
        "from scipy.stats import lognorm\n",
        "from scipy.optimize import minimize, rosen, rosen_der\n",
        "from scipy import special\n",
        "from scipy.stats import norm\n",
        "\n",
        "class FRAG_DRL:\n",
        "\n",
        "    def __init__(self, time_t=[], jacket_time=[], extender_time=[], shearKey_time=[], RC_time=[], EB_time=[], city_hazard = 0):\n",
        "\n",
        "\n",
        "        self.time_t=np.array(time_t)\n",
        "        self.extender_time=np.array(extender_time)\n",
        "        self.jacket_time= np.array(jacket_time)\n",
        "        self.shearKey_time= np.array(shearKey_time)\n",
        "        self.RC_time= np.array(RC_time)\n",
        "        self.EB_time= np.array(EB_time)\n",
        "        self.city_hazard = city_hazard\n",
        "\n",
        "\n",
        "    def mod_frag(pf,x,mod_factors):\n",
        "\n",
        "        f = lambda x,mu,sigma: scipy.stats.lognorm.cdf(x, sigma, loc=0, scale=np.exp(mu))\n",
        "        x0 = np.asarray([np.log(1.5), 0.001])\n",
        "        mu,sigma = scipy.optimize.curve_fit(f,x,pf,p0=x0,method='lm',maxfev=5000)[0]\n",
        "        mu=np.log(np.exp(mu)*mod_factors[0])\n",
        "        sigma=sigma*mod_factors[1]\n",
        "        pf_mod = scipy.stats.lognorm.cdf(x, sigma, loc=0, scale=np.exp(mu))\n",
        "        return pf_mod, mu,sigma\n",
        "\n",
        "\n",
        "    def fraglity (self,):\n",
        "        # To find the constant values, please refer to the paper \"Padgett J E, Dennemann K and Ghosh J 2010 Risk-based seismic life-cycle cost–benefit\n",
        "        #(LCC-B) analysis for bridge retrofit assessment Structural Safety 32 165–73 \"\n",
        "        frag_mod_factors_SJ= [1.03,1,1.16,1,1.17,1,1.20,1]\n",
        "        frag_mod_factors_EB= [2.94,1,1.31,1,1.21,1,1.17,1]\n",
        "        frag_mod_factors_RC= [1.04,1,0.96,1,1.01,1,1.05,1]\n",
        "        frag_mod_factors_SE= [1.01,1,1.00,1,1.00,1,1.31,1]\n",
        "        frag_mod_factors_SK= [1.01,1,0.98,1,0.99,1,1.01,1]\n",
        "        frag_mod_factors_RC_SK= [1.04,1,0.96,1,1.04,1,1.12,1]\n",
        "        frag_mod_factors_SE_SK= [1.01,1,0.97,1,0.99,1,1.37,1]\n",
        "        frag_mod_factors_SJ_SE= [1.03,1,1.16,1,1.17,1,1.31,1]\n",
        "        frag_mod_factors_SJ_SK= [1.03,1,1.16,1,1.17,1,1.37,1]\n",
        "        frag_mod_factors_SJ_SE_SK=[1.03,1,1.16,1,1.17,1,1.37,1]\n",
        "\n",
        "\n",
        "\n",
        "        PGA=np.linspace(np.log(0.01), np.log(3), 30)\n",
        "        PGA=np.exp(PGA)\n",
        "        size=PGA.size\n",
        "\n",
        "\n",
        "\n",
        "        lam_factor_complete_sys= np.zeros(size)\n",
        "        lam_factor_extensive_sys= np.zeros(size)\n",
        "        lam_factor_moderate_sys= np.zeros(size)\n",
        "        lam_factor_slight_sys= np.zeros(size)\n",
        "\n",
        "\n",
        "\n",
        "        # To find the constant values, please refer to the paper \"Padgett J E, Dennemann K and Ghosh J 2010 Risk-based seismic life-cycle cost–benefit\n",
        "        #(LCC-B) analysis for bridge retrofit assessment Structural Safety 32 165–73 \"\n",
        "        P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21))/0.69)\n",
        "        P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61))/0.60)\n",
        "        P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86))/0.60)\n",
        "        P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20))/0.61)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        x= Symbol('x')\n",
        "\n",
        "        if self.city_hazard == 0:\n",
        "            y2= 11.8246*sympy.exp(56.1606*((sympy.log(x/134.7200))**-1)) # it is for Memphis\n",
        "        elif self.city_hazard == 1:\n",
        "            y2= 66.1763*sympy.exp(48.3592*((sympy.log(x/47.2546))**-1)) # it is for San Fransisco\n",
        "        else:\n",
        "            print('If you want to analysis based on your desired city, \\\n",
        "            refer to USGS website (https://earthquake.usgs.gov/hazards/interactive/) and\\\n",
        "            paper entitled \"Improved seismic hazard model with application to probabilistic seismic demand analysis\"\\\n",
        "            to add the corresponding hazard curve')\n",
        "\n",
        "        y2prime=y2.diff(x)\n",
        "        yprime=y2prime\n",
        "        f = lambdify(x, yprime, 'numpy')\n",
        "\n",
        "        s=np.zeros(size)\n",
        "        s1 = np.zeros(size)\n",
        "\n",
        "\n",
        "\n",
        "        lam_factor_complete_sys= np.zeros(size)\n",
        "        lam_factor_extensive_sys= np.zeros(size)\n",
        "        lam_factor_moderate_sys= np.zeros(size)\n",
        "        lam_factor_slight_sys= np.zeros(size)\n",
        "\n",
        "\n",
        "\n",
        "        for sa in range (0,size):\n",
        "            s[sa]=np.abs(f(PGA[sa]))\n",
        "            if sa!=0:\n",
        "                s1[sa]=s[sa]*np.abs((PGA[sa]-PGA[sa-1]))\n",
        "\n",
        "\n",
        "        if self.time_t>=self.extender_time and self.time_t>=self.jacket_time and self.time_t>=self.shearKey_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SJ_SE_SK[0]))/(0.69*frag_mod_factors_SJ_SE_SK[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SJ_SE_SK[2]))/(0.60*frag_mod_factors_SJ_SE_SK[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SJ_SE_SK[4]))/(0.60*frag_mod_factors_SJ_SE_SK[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SJ_SE_SK[6]))/(0.61*frag_mod_factors_SJ_SE_SK[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.extender_time and self.time_t>=self.jacket_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SJ_SE[0]))/(0.69*frag_mod_factors_SJ_SE[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SJ_SE[2]))/(0.60*frag_mod_factors_SJ_SE[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SJ_SE[4]))/(0.60*frag_mod_factors_SJ_SE[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SJ_SE[6]))/(0.61*frag_mod_factors_SJ_SE[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.shearKey_time and self.time_t>=self.jacket_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SJ_SK[0]))/(0.69*frag_mod_factors_SJ_SK[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SJ_SK[2]))/(0.60*frag_mod_factors_SJ_SK[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SJ_SK[4]))/(0.60*frag_mod_factors_SJ_SK[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SJ_SK[6]))/(0.61*frag_mod_factors_SJ_SK[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.extender_time and self.time_t>=self.shearKey_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SE_SK[0]))/(0.69*frag_mod_factors_SE_SK[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SE_SK[2]))/(0.60*frag_mod_factors_SE_SK[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SE_SK[4]))/(0.60*frag_mod_factors_SE_SK[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SE_SK[6]))/(0.61*frag_mod_factors_SE_SK[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.RC_time and self.time_t>=self.shearKey_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_RC_SK[0]))/(0.69*frag_mod_factors_RC_SK[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_RC_SK[2]))/(0.60*frag_mod_factors_RC_SK[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_RC_SK[4]))/(0.60*frag_mod_factors_RC_SK[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_RC_SK[6]))/(0.61*frag_mod_factors_RC_SK[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.shearKey_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SK[0]))/(0.69*frag_mod_factors_SK[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SK[2]))/(0.60*frag_mod_factors_SK[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SK[4]))/(0.60*frag_mod_factors_SK[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SK[6]))/(0.61*frag_mod_factors_SK[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "\n",
        "        elif self.time_t>=self.extender_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SE[0]))/(0.69*frag_mod_factors_SE[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SE[2]))/(0.60*frag_mod_factors_SE[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SE[4]))/(0.60*frag_mod_factors_SE[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SE[6]))/(0.61*frag_mod_factors_SE[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.RC_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_RC[0]))/(0.69*frag_mod_factors_RC[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_RC[2]))/(0.60*frag_mod_factors_RC[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_RC[4]))/(0.60*frag_mod_factors_RC[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_RC[6]))/(0.61*frag_mod_factors_RC[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "\n",
        "        elif self.time_t>=self.EB_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_EB[0]))/(0.69*frag_mod_factors_EB[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_EB[2]))/(0.60*frag_mod_factors_EB[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_EB[4]))/(0.60*frag_mod_factors_EB[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_EB[6]))/(0.61*frag_mod_factors_EB[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "        elif self.time_t>=self.jacket_time:\n",
        "\n",
        "\n",
        "            P_slight_sys = norm.cdf((np.log(PGA)-np.log(0.21*frag_mod_factors_SJ[0]))/(0.69*frag_mod_factors_SJ[1]))\n",
        "            P_moderate_sys = norm.cdf((np.log(PGA)-np.log(0.61*frag_mod_factors_SJ[2]))/(0.60*frag_mod_factors_SJ[3]))\n",
        "            P_extensive_sys = norm.cdf((np.log(PGA)-np.log(0.86*frag_mod_factors_SJ[4]))/(0.60*frag_mod_factors_SJ[5]))\n",
        "            P_complete_sys = norm.cdf((np.log(PGA)-np.log(1.20*frag_mod_factors_SJ[6]))/(0.61*frag_mod_factors_SJ[7]))\n",
        "\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "\n",
        "            lam_factor_complete_sys= s1*P_complete_sys\n",
        "            lam_factor_extensive_sys= s1*P_extensive_sys\n",
        "            lam_factor_moderate_sys= s1*P_moderate_sys\n",
        "            lam_factor_slight_sys= s1*P_slight_sys\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        annual_rate_slight_sys=sum(lam_factor_slight_sys)\n",
        "        annual_rate_moderate_sys=sum(lam_factor_moderate_sys)\n",
        "        annual_rate_extensive_sys=sum(lam_factor_extensive_sys)\n",
        "        annual_rate_complete_sys=sum(lam_factor_complete_sys)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        PT_slight_sys=1-np.exp(-annual_rate_slight_sys)\n",
        "        PT_moderate_sys=1-np.exp(-annual_rate_moderate_sys)\n",
        "        PT_extensive_sys=1-np.exp(-annual_rate_extensive_sys)\n",
        "        PT_complete_sys=1-np.exp(-annual_rate_complete_sys)\n",
        "\n",
        "\n",
        "\n",
        "        PP_sys=[1-(PT_slight_sys), -PT_moderate_sys+PT_slight_sys, -PT_extensive_sys+PT_moderate_sys,-PT_complete_sys+PT_extensive_sys, PT_complete_sys]\n",
        "\n",
        "        P_sys = PP_sys\n",
        "\n",
        "        return P_sys\n",
        "\n"
      ],
      "metadata": {
        "id": "ecUI1qU7mrbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Bridge Environment is developed here\n",
        "@author: Alireza Ghavidel\n",
        "\"\"\"\n",
        "\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import random\n",
        "#from Fragility_risk_analysis import FRAG_DRL\n",
        "from copy import deepcopy\n",
        "\n",
        "class BridgeEnvFrg(Env):\n",
        "    def __init__(self, life, city):\n",
        "\n",
        "        # lets consider the order as following for components:\n",
        "        # \"0\": Deck, \"1\":Super structure, \"2\": Sub structure,\n",
        "        # Actions: we can take : Do nothing, Minor, Major and replacement\n",
        "        self.action_space = Discrete(64) # 64: 4*4*4 actions //// 4 actions [do nothing, minor, major, replacement] for deck, superstructure and substructure\n",
        "        # observation array\n",
        "        self.observation_space = Box(low=np.array([0, 0, 0]), high=np.array([8,8,8]), shape = (3,), dtype=np.int64) # [Deck 0-8, Sperstructure 0-8, Substructure 0-8]\n",
        "        # Set start state\n",
        "        self.state = np.zeros(shape=(3,),dtype = np.int64)\n",
        "        self.state[0:3] =  np.random.randint(4,[9,9,9])    # initiating the initial state from the fair condition randomly\n",
        "        self.total_steps = 0 # counting\n",
        "        self.componenets = 3 # number of components\n",
        "        self.life = life # life horizon\n",
        "        self.city = city # city for risk analysis: 0: Memphis, 1: San Francisco\n",
        "        self.damage = 0\n",
        "\n",
        "\n",
        "    def step(self, action, Deck_area, L_d, ADT, r_Truck, jacketing = False, jacketing_t = 100, extender = False, extender_t = 100, shearKey = False, shearKey_t = 100, w1=0.05):\n",
        "        # Markov transition matrices can be modified by the user if needed\n",
        "        # condition-based rating\n",
        "        state_old = deepcopy(self.state)\n",
        "        trans = np.zeros(shape=[self.componenets,4,9,9])  # 3 comps, 4 actions, 9 states\n",
        "        # Do nothing\n",
        "        trans [0, 0] = [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0114, 0.9886, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0174, 0.9826, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0227, 0.9773, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0268, 0.9732, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0714, 0.9286, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0452, 0.1011, 0.8537]]\n",
        "\n",
        "        trans [1, 0] = [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0282, 0.9718, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0107, 0.9893, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0147, 0.9853, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0194, 0.9806, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0246, 0.9754, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0276, 0.9724, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0532, 0.9468, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0282, 0.0995, 0.8723]]\n",
        "\n",
        "        trans [2, 0] = [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0142, 0.9858, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0208, 0.9792, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0302, 0.9698, 0.0000, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0282, 0.9718, 0.0000, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0207, 0.9793, 0.0000, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0654, 0.9346, 0.0000],\n",
        "                        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0349, 0.0925, 0.8726]]\n",
        "\n",
        "\n",
        "        # Minor maintenance\n",
        "        trans [0:3, 1] = [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.9, 0.1, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.80, 0.20, 0.0, 0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.4],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]\n",
        "\n",
        "        # Major Maintenance\n",
        "        trans [0:3, 2] = [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.3, 0.4, 0.3, 0.0, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 0.1, 0.3, 0.6, 0.0, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.1, 0.2, 0.7, 0.0, 0.0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.1, 0.85, 0],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.05, 0.9],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.02, 0.98],\n",
        "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]\n",
        "\n",
        "\n",
        "\n",
        "        # Replace\n",
        "        trans [0:3,3,:,8] = 1\n",
        "\n",
        "        # unravel actions\n",
        "        action_index = np.unravel_index(action,(4,4,4))  # (deck, superstructure, substructure, column, bearing, abutment, retrofitting combinations )\n",
        "        action_index = np.asarray(action_index)\n",
        "\n",
        "        # Damage State (DS) only reflect the DS happened in each year based on the seismic risk model. We don't propagate the DS to the next year\n",
        "        self.damage = 0\n",
        "\n",
        "\n",
        "        # Retrofitting configuration: we have 3 possible retrofitting actions: Seat extender, steel jacketing, and shear key\n",
        "        if extender == True:\n",
        "            self.extender_time = extender_t\n",
        "        else:\n",
        "            self.extender_time = []\n",
        "        if jacketing == True:\n",
        "            self.jacket_time = jacketing_t\n",
        "        else:\n",
        "            self.jacket_time = []\n",
        "        if shearKey == True:\n",
        "            self.shearKey_time = shearKey_t\n",
        "        else:\n",
        "            self.shearKey_time = []\n",
        "\n",
        "\n",
        "        # here we call the fragility and risk analysis part to get the damage state probabilities\n",
        "        FRG=FRAG_DRL(time_t=self.total_steps, jacket_time=self.jacket_time, extender_time=self.extender_time, shearKey_time=self.shearKey_time, RC_time=[], EB_time=[], city_hazard = self.city)\n",
        "        P_sys=FRG.fraglity()\n",
        "\n",
        "\n",
        "\n",
        "        # this part the next state is calculated based on the transition probabilities come from Markov matrices and fragility functions\n",
        "        for component in range(self.componenets):\n",
        "            self.state[component] = np.random.choice(9, p=trans[component][action_index[component]][self.state[component]])\n",
        "\n",
        "        # Earthquake damage type\n",
        "        self.damage = np.random.choice(5, p=P_sys)\n",
        "\n",
        "\n",
        "\n",
        "        # Mapping DS to CR\n",
        "        state_update = deepcopy(self.state)\n",
        "\n",
        "        if self.damage == 0:\n",
        "            self.state[0] = state_update[0]\n",
        "            self.state[1] = state_update[1]\n",
        "            self.state[2] = state_update[2]\n",
        "\n",
        "        elif self.damage == 1:\n",
        "            self.state[0] = np.min([state_update[0],6])\n",
        "            self.state[1] = np.min([state_update[1],6])\n",
        "            self.state[2] = np.min([state_update[2],6])\n",
        "\n",
        "        elif self.damage == 2:\n",
        "            self.state[0] = np.min([state_update[0],4])\n",
        "            self.state[1] = np.min([state_update[1],4])\n",
        "            self.state[2] = np.min([state_update[2],4])\n",
        "\n",
        "        elif self.damage == 3:\n",
        "            self.state[0] = np.min([state_update[0],3])\n",
        "            self.state[1] = np.min([state_update[1],3])\n",
        "            self.state[2] = np.min([state_update[2],3])\n",
        "\n",
        "        elif self.damage == 4:\n",
        "            self.state[0] = 0\n",
        "            self.state[1] = 0\n",
        "            self.state[2] = 0\n",
        "\n",
        "\n",
        "        # update CS based on actions\n",
        "\n",
        "        if action_index[1]==3:\n",
        "            self.state[0]=8\n",
        "            self.state[1]=8\n",
        "        if action_index[2]==3:\n",
        "            self.state[0] = 8\n",
        "            self.state[1] = 8\n",
        "            self.state[2] = 8\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"Calculate reward'\"\"\"\n",
        "        # Costant values for reward calculations can be adjusted by the user, if needed\n",
        "        # Residual serviceability based on current action\n",
        "        if max(action_index[0:3]) ==0: # Do nothing\n",
        "            T1 = 0.0\n",
        "            alpha1 = 1.0\n",
        "        elif max(action_index[0:3])==1: # Minor maintenance\n",
        "            T1 = 7.0\n",
        "            alpha1 = 0.75\n",
        "        elif max(action_index[0:3])==2: # Major maintenance\n",
        "            T1 = 30.0\n",
        "            alpha1 = 0.5\n",
        "        else:                           # replace\n",
        "            T1 = 182.0\n",
        "            alpha1 = 0.0\n",
        "\n",
        "        T_CR = T1\n",
        "        alpha_CR = alpha1\n",
        "\n",
        "        # final T and alpha from different maintenance actions and different damage states\n",
        "        T = T_CR\n",
        "        alpha = alpha_CR\n",
        "\n",
        "\n",
        "        # Bridge total construction costs\n",
        "        C_b = 160.19 # Bridge construction cost rate $/ft2 deck area for Tennessee\n",
        "        C_Bridge = Deck_area*C_b * 10.764  # 10.764 convert from meter square to feet square\n",
        "\n",
        "        # Retrofitting costs (Huang Y, Parmelee S and Pang W 2014 Optimal retrofit scheme for highway network under seismic hazards\n",
        "        #International Journal of Transportation Science and Technology 3 109–28)\n",
        "        steel_jacketing_unit = 0.12  #\n",
        "        C_jacketing = steel_jacketing_unit *  C_Bridge\n",
        "        C_seat_extender= 0.03 * C_Bridge\n",
        "        C_shear_key= 0.03 * C_Bridge\n",
        "        C_bearing = 0.05 * C_Bridge\n",
        "        \"\"\" Direct agency costs \"\"\"\n",
        "        # refer to \"Elbehairy H 2007 Bridge management system with integrated life cycle cost optimization\"\n",
        "        Cost_matrix = np.zeros(shape=(3,4))\n",
        "        Cost_matrix[0:3,0] = 0.0                                    # Components: Deck, superstructure, substructure / action: do nothing\n",
        "        Cost_matrix[0,1] = 0.05*C_Bridge * 0.225                    # Components: Deck / action: minor\n",
        "        Cost_matrix[1,1] = 0.05*C_Bridge * 0.263                    # Components: superstructure  / action: minor\n",
        "        Cost_matrix[2,1] = 0.05*C_Bridge * 0.412                    # Components: substructure / action: minor\n",
        "        Cost_matrix[0,2] = 0.25*C_Bridge * 0.225                    # Components: Deck / action: major\n",
        "        Cost_matrix[1,2] = 0.25*C_Bridge * 0.263                    # Components: superstructure / action: major\n",
        "        Cost_matrix[2,2] = 0.25*C_Bridge * 0.412                    # Components: substructure / action: major\n",
        "        Cost_matrix[0,3] = 1.1*C_Bridge * 0.225                     # Components: Deck / action: rebuild\n",
        "        Cost_matrix[1,3] = 1.1*C_Bridge * (0.263 + 0.225)           # Components: superstructure / action: rebuild\n",
        "        Cost_matrix[2,3] = 1.1*C_Bridge * (0.412 + 0.263 + 0.225)   # Components: substructure / action: rebuild\n",
        "\n",
        "\n",
        "        C_CR = 0.0\n",
        "        C_Ret = 0.0\n",
        "        for i in range(0,3):  # Summation over all the 3 components\n",
        "            C_CR += Cost_matrix[i,int(action_index[i])]\n",
        "\n",
        "        C_j = 0.0\n",
        "        C_ex= 0.0\n",
        "        C_sk = 0.0\n",
        "        if jacketing == True and self.total_steps==np.asarray(self.jacket_time):\n",
        "            C_j = C_jacketing\n",
        "        else:\n",
        "            C_j=0.0\n",
        "\n",
        "        if extender == True and self.total_steps==np.asarray(self.extender_time):\n",
        "            C_ex = C_seat_extender\n",
        "        else:\n",
        "            C_ex = 0.0\n",
        "\n",
        "        if shearKey == True and self.total_steps==np.asarray(self.shearKey_time):\n",
        "            C_sk = C_shear_key\n",
        "        else:\n",
        "            C_sk = 0.0\n",
        "\n",
        "        C_Ret = C_j + C_ex + C_sk\n",
        "        C_Direct = 0\n",
        "        C_Direct = C_CR + C_Ret\n",
        "\n",
        "\n",
        "        if C_Direct > 1.1*C_Bridge:   # Avoid double counting the reconstruction action\n",
        "            C_Direct = 1.1*C_Bridge\n",
        "        \"\"\" Indirect social costs \"\"\" # the constat values can be changed by the user\n",
        "        L_d = L_d * 0.621371     # 0.621371 converts km to mile\n",
        "        C_O_Car = 0.64 # Running cost for car ($/car/mile)\n",
        "        C_O_Truck = 1.855 # Running cost for truck ($/truck/mile)\n",
        "        C_W_Car = 12.35 # Time costs for car passengers ($/hr/passenger)\n",
        "        C_W_Truck = 31.05 # Time costs for trucks ($/hr/truck)\n",
        "        O_Car = 1.67 # Number of passengers per car\n",
        "        V_d = 50 # Detour speed mph\n",
        "\n",
        "        # Determine percentage of detoured traffic due to serviceability loss (before the action)\n",
        "\n",
        "        if state_old[0] >= 6: # deck\n",
        "            phi_deck_old = 1\n",
        "        elif state_old[0] >= 4 and state_old[0] < 6: # Deck\n",
        "            phi_deck_old = 1 - (((6-state_old[0])/6)*0.75)\n",
        "        else:\n",
        "            phi_deck_old = 0.0\n",
        "\n",
        "        if state_old[1] >= 4: # Superstructure\n",
        "            phi_girder_old = 1.0\n",
        "        else:\n",
        "            phi_girder_old = 0.0\n",
        "\n",
        "        if state_old[2] >= 4: # Substructure\n",
        "            phi_sub_old = 1.0\n",
        "        else:\n",
        "            phi_sub_old = 0.0\n",
        "\n",
        "        phi_old1 = min(phi_deck_old,phi_girder_old,phi_sub_old)\n",
        "\n",
        "\n",
        "        phi_old = phi_old1\n",
        "\n",
        "        # Indirect operation costs for all\n",
        "\n",
        "        C_O = (C_O_Car*(1-r_Truck) + C_O_Truck*r_Truck)*L_d*ADT*((1-alpha*phi_old)*T + (1-phi_old)*(365-T))\n",
        "        # Indirect time costs\n",
        "        C_T = (C_W_Car*O_Car*(1-r_Truck) + C_W_Truck*r_Truck)*ADT*L_d/V_d*((1-alpha*phi_old)*T + (1-phi_old)*(365-T))\n",
        "        # Total indirect costs\n",
        "        C_Indirect = C_O + C_T\n",
        "\n",
        "        # Calculate reward\n",
        "        C_Indirect = 1.43 * C_Indirect # 1.43 is a factor to consider safety cost (accidents)\n",
        "        reward = -(C_Direct + (w1 * C_Indirect)) # Negative of the total cost as the reward, w1 is the agency weighting factor\n",
        "\n",
        "         # go to the next year\n",
        "        self.total_steps +=1\n",
        "\n",
        "        # Check it is done\n",
        "        if self.total_steps  == self.life:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        # Set placeholder for info\n",
        "        info = {}\n",
        "\n",
        "        # Return step information\n",
        "        return self.state, C_Direct, C_Indirect,reward, done, info,self.damage\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        # Implement viz\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros(shape=(3,),dtype = np.int64)\n",
        "        self.state[0:3] = np.random.randint(4,[9,9,9])\n",
        "        self.total_steps = 0\n",
        "        self.damage = 0\n",
        "\n",
        "        return self.state\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "guZTEuFVmvja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Parameterized DQN with Prioritized Experience Replay Memory (PER)\n",
        "@authors: Dr. Ao Du and Alireza Ghavidel\n",
        "\n",
        "\"\"\"\n",
        "#!pip install gym\n",
        "#import gymnasium as gym\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "\n",
        "time_jacketing= 0 # if there is steel jaketing retrofitting, please specify what year happened (when steel jacekting is \"True\")\n",
        "time_extender= 0 # when seat_extender = True, please specify the year\n",
        "time_shearKey= 0 # when seat_extender = True, please specify the year\n",
        "#from Bridge_Environment import BridgeEnvFrg\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "env = BridgeEnvFrg(life = life_span, city = City)\n",
        "state_shape = env.observation_space.shape\n",
        "n_params = int(4)\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if GPU is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device', device)\n",
        "## Replay Memory\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward', 'A_deck','L_D','ADT','r_truck'))\n",
        "\n",
        "\n",
        "class PrioritizedReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity, alpha=0.6, beta=0.4, beta_annealing=0.001):\n",
        "        #alpha, beta, beta_annealing: Parameters used in prioritized experience replay.\n",
        "        #alpha determines how much priority influences the sampling probability,\n",
        "        #while beta and beta_annealing are used to control importance weights\n",
        "        self.capacity = capacity\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.beta_annealing = beta_annealing\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "        self.priorities = deque([], maxlen=capacity)\n",
        "        self.position = 0\n",
        "        self.size = 0  # Initialize size counter\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        transition = Transition(*args)\n",
        "        max_priority = max(self.priorities) if self.priorities else 1.0\n",
        "        if self.size < self.capacity:  # Check if not at max capacity\n",
        "            self.size += 1\n",
        "        else:\n",
        "            self.memory.popleft()  # Remove oldest transition\n",
        "            self.priorities.popleft()  # Remove oldest priority\n",
        "        self.memory.append(transition)\n",
        "        self.priorities.append(max_priority)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        prios = np.array(self.priorities)\n",
        "        probs = prios ** self.alpha\n",
        "        probs /= probs.sum()\n",
        "\n",
        "        indices = np.random.choice(len(self.memory), batch_size, p=probs)\n",
        "        samples = [self.memory[idx] for idx in indices]\n",
        "\n",
        "        beta = self.beta + self.beta_annealing\n",
        "        importance_weights = (len(self.memory) * probs[indices]) ** (-beta)\n",
        "        importance_weights /= importance_weights.max()\n",
        "\n",
        "        return samples, indices, importance_weights\n",
        "\n",
        "    def update_priorities(self, indices, priorities):\n",
        "        for idx, priority in zip(indices, priorities):\n",
        "            self.priorities[idx] = priority\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "# DQN Agent\n",
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_inputs, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_inputs, 24)\n",
        "        self.layer2 = nn.Linear(24, 24)\n",
        "        self.layer3 = nn.Linear(24, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)\n",
        "\n",
        "def select_action(inputs):\n",
        "    global i_episode, previous_actions_deck, previous_actions_super, previous_actions_sub, test_on\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * i_episode / EPS_DECAY)\n",
        "\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            inputs_cpu = inputs.to('cpu').numpy()\n",
        "            action_values = policy_net(inputs)\n",
        "            max_action = action_values.max(1)[1]  # Get the index of the maximum action\n",
        "\n",
        "            # Convert max_action to a numpy array and then unravel it\n",
        "            max_action_numpy = max_action.cpu().detach().numpy()\n",
        "            modified_action = np.asarray(np.unravel_index(max_action_numpy, (4, 4, 4)))\n",
        "\n",
        "            if test_on == 1:\n",
        "                if inputs_cpu[0][0] >= 6 :\n",
        "                    modified_action[0] = 0\n",
        "\n",
        "                if inputs_cpu[0][1] >= 6 :\n",
        "                    modified_action[1] = 0\n",
        "\n",
        "                if inputs_cpu[0][2] >= 6 :\n",
        "                    modified_action[2] = 0\n",
        "            # Constraint: Check the previous actions for each component\n",
        "\n",
        "            if any(action != 0 for action in  previous_actions_deck) and inputs_cpu[0][0] >= 4:\n",
        "                modified_action[0] = 0  # Update to \"Do Nothing\" if constraint is violated\n",
        "\n",
        "            if any(action != 0 for action in previous_actions_super) and inputs_cpu[0][1] >= 4:\n",
        "                modified_action[1] = 0\n",
        "\n",
        "            if any(action != 0 for action in previous_actions_sub) and inputs_cpu[0][2] >= 4:\n",
        "                modified_action[2] = 0\n",
        "\n",
        "\n",
        "            # uppdate the suggested action based on the correlation of components\n",
        "            if modified_action[2] == 3:\n",
        "                modified_action[0] = 3\n",
        "                modified_action[1] = 3\n",
        "\n",
        "            if modified_action[1] == 3:\n",
        "                modified_action[0] = 3\n",
        "\n",
        "\n",
        "            previous_actions_deck.append(modified_action[0])\n",
        "\n",
        "            previous_actions_super.append(modified_action[1])\n",
        "\n",
        "            previous_actions_sub.append(modified_action[2])\n",
        "\n",
        "            return torch.tensor([np.asarray(np.ravel_multi_index(modified_action, (4, 4, 4)))], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Exploration: Choose a random action\n",
        "        random_action = env.action_space.sample()\n",
        "        modified_action = np.asarray(np.unravel_index(random_action, (4, 4, 4)))\n",
        "        inputs_cpu = inputs.to('cpu').numpy()\n",
        "\n",
        "\n",
        "        # Update the previous_actions list for each component\n",
        "        previous_actions_deck.append(modified_action[0])\n",
        "\n",
        "        previous_actions_super.append(modified_action[1])\n",
        "\n",
        "        previous_actions_sub.append(modified_action[2])\n",
        "\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "print('Trainig started')\n",
        "policy_net = DQN(n_observations+n_params,n_actions).to(device)\n",
        "target_net = DQN(n_observations+n_params,n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1250, gamma=0.95)\n",
        "memory = PrioritizedReplayMemory(int(1e5))\n",
        "target_model_update = int(40)\n",
        "\n",
        "i_episode = 0;\n",
        "test_on = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "episode_reward = []\n",
        "\n",
        "## Plot training curves\n",
        "def plot_training(show_result=False):\n",
        "    plt.figure(1)\n",
        "    metric_temp = torch.tensor(episode_reward, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Episode cumulative cost')\n",
        "    plt.plot(metric_temp.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(metric_temp) >= 50:\n",
        "        means = metric_temp.unfold(0, 50, 1).mean(1).view(-1)\n",
        "        #means = torch.cat((torch.zeros(49), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())\n",
        "\n",
        "\n",
        "\n",
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    # Sample a batch from the prioritized replay memory\n",
        "    transitions, indices, weights = memory.sample(BATCH_SIZE)\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                            batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                      if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "    A_Deck_batch = torch.cat(batch.A_deck)\n",
        "    L_D_batch = torch.cat(batch.L_D)\n",
        "    ADT_batch = torch.cat(batch.ADT)\n",
        "    r_truck_batch = torch.cat(batch.r_truck)\n",
        "    input_batch = torch.hstack((state_batch, A_Deck_batch, L_D_batch, ADT_batch, r_truck_batch))\n",
        "\n",
        "    state_action_values = policy_net(input_batch).gather(1, action_batch)\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        input_batch_target = torch.hstack((non_final_next_states, A_Deck_batch[non_final_mask],\n",
        "                                          L_D_batch[non_final_mask], ADT_batch[non_final_mask],\n",
        "                                          r_truck_batch[non_final_mask]))\n",
        "        next_state_values[non_final_mask] = target_net(input_batch_target).max(1)[0]\n",
        "\n",
        "\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    # Compute Huber loss\n",
        "    loss = criterion(state_action_values, torch.tensor(expected_state_action_values, dtype=torch.float32).unsqueeze(1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update priorities in the memory\n",
        "    updated_priorities = torch.abs(expected_state_action_values - state_action_values.squeeze(1))\n",
        "    updated_priorities = updated_priorities.cpu().detach().numpy()\n",
        "    memory.update_priorities(indices, updated_priorities)\n",
        "\n",
        "\n",
        "# Latin Hypercube Sampling of bridge random parameters\n",
        "from scipy.stats import qmc\n",
        "LHS_sampler = qmc.LatinHypercube(d=n_params)\n",
        "LHS_samples = LHS_sampler.random(n=num_episodes)\n",
        "\n",
        "# Convert the LHS sample into each marginal distributions\n",
        "deck_area_LHS = 100 + (1200-100)*LHS_samples[:,0]\n",
        "L_d_LHS = 0.5 + (20-0.5)*LHS_samples[:,1]\n",
        "ADT_LHS = 500 + (20000-500)*LHS_samples[:,2]\n",
        "r_Truck_LHS = 0.00 + (0.18-0.00)*LHS_samples[:,3]\n",
        "\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    scheduler.step()\n",
        "\n",
        "    state = env.reset()\n",
        "\n",
        "    deck_area = deck_area_LHS[i_episode]\n",
        "    L_d = L_d_LHS[i_episode]\n",
        "    ADT = ADT_LHS[i_episode]\n",
        "    r_Truck = r_Truck_LHS[i_episode]\n",
        "\n",
        "\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    deck_area = torch.tensor([deck_area], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    L_d = torch.tensor([L_d], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    ADT = torch.tensor([ADT], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    r_Truck = torch.tensor([r_Truck], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "    episode_reward_temp = 0.0\n",
        "    terminated = False\n",
        "\n",
        "    previous_actions_deck = deque([], maxlen=5)\n",
        "    previous_actions_super = deque([], maxlen=5)\n",
        "    previous_actions_sub = deque([], maxlen=5)\n",
        "\n",
        "    t = int(0)\n",
        "    while not terminated:\n",
        "        input_temp = torch.hstack((state, deck_area, L_d, ADT, r_Truck))\n",
        "        input_temp = input_temp.to(device)  # Ensure data is on the correct device\n",
        "        action = select_action(input_temp)\n",
        "        observation, _,_,reward, terminated, _,damage= env.step(action.item(), deck_area.item(), L_d.item(), ADT.item(), r_Truck.item(), jacketing = steel_lacketing, jacketing_t = time_jacketing, extender = seat_extender, extender_t = time_extender, shearKey = shear_key, shearKey_t = time_shearKey, w1=w1)\n",
        "        episode_reward_temp += reward * (GAMMA ** t)\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated\n",
        "        t += 1\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward, deck_area, L_d, ADT, r_Truck)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        if done:\n",
        "            episode_reward.append(-episode_reward_temp)\n",
        "            plot_training()\n",
        "            break\n",
        "\n",
        "    # Update the target model every target_model_update episodes\n",
        "    if i_episode % target_model_update == 0:\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "############### Save the trained model (AI-agent) for later use ###############\n",
        "###############################################################################\n",
        "print('Trainig completed')\n",
        "\n",
        "torch.save(policy_net.state_dict(), 'Trained_model.pth') # Save model\n",
        "np.save('Trained_model',episode_reward) # save the training results\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "plot_training(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "rpD0cMERmw15",
        "outputId": "97674972-5126-442a-b8fb-7477223ea348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-47ee40703a04>\u001b[0m in \u001b[0;36m<cell line: 297>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0minput_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure data is on the correct device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdamage\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeck_area\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_Truck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacketing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteel_lacketing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacketing_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_jacketing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseat_extender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextender_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_extender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshearKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshear_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshearKey_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_shearKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mepisode_reward_temp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGAMMA\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e8fc07fa4aa8>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, Deck_area, L_d, ADT, r_Truck, jacketing, jacketing_t, extender, extender_t, shearKey, shearKey_t, w1)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# here we call the fragility and risk analysis part to get the damage state probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mFRG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFRAG_DRL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacket_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacket_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextender_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextender_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshearKey_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshearKey_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRC_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEB_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcity_hazard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mP_sys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraglity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-e5b4b340094e>\u001b[0m in \u001b[0;36mfraglity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0my2prime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0myprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my2prime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambdify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/utilities/lambdify.py\u001b[0m in \u001b[0;36mlambdify\u001b[0;34m(args, expr, modules, printer, use_imps, dummify, cse, docstring_limit)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mcses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_expr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m     \u001b[0mfuncstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuncprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;31m# Collect the module imports from the code printers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/utilities/lambdify.py\u001b[0m in \u001b[0;36mdoprint\u001b[0;34m(self, funcname, args, expr, cses)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0mfuncbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exprrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exprrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mstr_expr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_recursive_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exprrepr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr_expr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/utilities/lambdify.py\u001b[0m in \u001b[0;36m_recursive_to_string\u001b[0;34m(doprint, arg)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatrixBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36mdoprint\u001b[0;34m(self, expr, assign_to)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# format the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/printer.py\u001b[0m in \u001b[0;36m_print\u001b[0;34m(self, expr, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mprintmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprintmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mprintmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Unknown object, fall back to the emptyPrinter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memptyPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m_print_Mul\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_coeff_Mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_keep_coeff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/numbers.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumberSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__gt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Frel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpf_lt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mExpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/numbers.py\u001b[0m in \u001b[0;36m_Frel\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Frel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sympify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSympifyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/sympify.py\u001b[0m in \u001b[0;36m_sympify\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \"\"\"\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/sympify.py\u001b[0m in \u001b[0;36msympify\u001b[0;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sympy_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuperclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/core/cache.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unhashable type:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}